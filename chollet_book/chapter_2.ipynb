{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning with Python - Francois Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2. Before we begin: the mathematical building blocks of neural networks\n",
    "\n",
    "This chapter covers:\n",
    "- A first example of a neural network\n",
    "- Tensors and tensor operations\n",
    "- How neural networks learn via backpropagation and gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST database and see its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: uint8 (60000, 28, 28). (Min, Max) = (0, 255)\n",
      "Train labels: uint8 (60000,). Classes = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train images: {train_images.dtype} {train_images.shape}. (Min, Max) = ({train_images.min()}, {train_images.max()})\")\n",
    "print(f\"Train labels: {train_labels.dtype} {train_labels.shape}. Classes = {set(train_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network architecture:\n",
    "- 1 hidden layer (dense) with 512 neurons and ReLU activation function.\n",
    "- 1 output layer (dense) with 10 neurons (one for each class) and Softmax activation function.\n",
    "\n",
    "Note: A dense layer is also called fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Book bug:\n",
    "# book command: $ network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "# Error: Use Input layer instead of Dense layer for input layer\n",
    "# Solution: $ network.add(layers.Input(shape=(28 * 28,))) \n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Input(shape=(28 * 28,)))\n",
    "network.add(layers.Dense(512, activation='relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the network ready for training, we need to pick three more things, as part of the compilation step:\n",
    "- *A loss function*: How the netowork will be able to measure its performance on the training data, and thus how it will be able to steer itself in the right direction.\n",
    "- *An optimizer*: The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "- *Metrics to monitor during training and testing*: Here, we will only care about accuracy (the fraction of the images that were correctly classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the image data and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# It's like the hot ecoding in pytorch\n",
    "# 5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. Show the accuracy and the loss over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.4411\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.1169\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0734\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0504\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a4df8100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the model performance over the test set.\n",
    "\n",
    "The tets-set accuracy turns out to be 97.8%, that's quite bit lower than the training set accuracy.\n",
    "This gap between training accuracy and test accuracy is an example of *overfitting*, the fact that machine-learning \n",
    "models tend to perform worse on new data than on their training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.9756 - loss: 0.0754\n",
      "Test accuracy: 97.84%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {100*test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data representation for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scalars (0D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x array = 12 with dimension 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(12)\n",
    "print(f\"x array = {x} with dimension {x.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectors (1D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x array = [12  3  6 14] with dimension 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14])\n",
    "print(f\"x array = {x} with dimension {x.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrices (2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x array = [[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 36  2]] with dimension 2\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "print(f\"x array = {x} with dimension {x.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3D tensors and higher-dimensional tensors\n",
    "\n",
    "If you pack such matrices in a new array, you obtain a 3D tensor, wich you can visually interpret as a cube of numbers. Following is a Numpy 3D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x array with dimension 3\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "print(f\"x array with dimension {x.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key attributes\n",
    "\n",
    "- *Number of axes (*rank*): For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor's `ndim` in Python libraries such as Numpy.\n",
    "- *Shape*: This is a tuple of integers that describes how many dimensions the tensors has along each axis. For instance, the previous matrix example has shape `(3, 5)`, and the 3D tensor example has shape `(3, 3, 5)`. A vector has a shape with a single element, such as `(5,)`, whereas a scalar has an empty shape, `()`.\n",
    "- *Data type* (usually called `dtype` in Python libraries). This is the type of the data contained in the tensor; for instance, a tensor's type could be `float32`, `uint8`, `float64`, and son on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images dimension:\t3\n",
      "Train images shape:\t(60000, 28, 28)\n",
      "Train images dtype:\tuint8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train images dimension:\\t{train_images.ndim}\")\n",
    "print(f\"Train images shape:\\t{train_images.shape}\")\n",
    "print(f\"Train images dtype:\\t{train_images.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying the fourth digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_images[4]\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice shape: (90, 28, 28)\n",
      "Slice shape: (90, 28, 28)\n",
      "Slice shape: (90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "my_slice = train_images[10:100]\n",
    "print(f\"Slice shape: {my_slice.shape}\")\n",
    "\n",
    "# Equivalent to the above\n",
    "my_slice = train_images[10:100, :, :]\n",
    "print(f\"Slice shape: {my_slice.shape}\")\n",
    "\n",
    "# Equivalent to the above\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "print(f\"Slice shape: {my_slice.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice shape: (60000, 14, 14)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice shape: (60000, 14, 14)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select 14x14 pixels in the bottom-right corner of all images\n",
    "my_slice = train_images[:, 14:, 14:]\n",
    "print(f\"Slice shape: {my_slice.shape}\")\n",
    "digit = my_slice[4]\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# Select 14x14 pixels in the middle of all images\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "print(f\"Slice shape: {my_slice.shape}\")\n",
    "digit = my_slice[4]\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The notion of data batches\n",
    "In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you will come across in deep learning will be the *sample axis* (sometimes called the *sample dimension*). In the MNIST example, samples are images of digits.\n",
    "\n",
    "In addition, deep learning models don't process an entire dataset at once; rather, they break the data into small batches. Concretely, here's one batch of our MNIST digits, with batch size of 128.\n",
    "\n",
    "When considering such a batch tensor, the first axis (axis 0) is called the *batch axis* or *batch dimension*. This is a term you will frequently encounter when using Keras and other deep learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[:128]      # 1st batch\n",
    "batch = train_images[128:256]   # 2nd batch\n",
    "\n",
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]   # nth batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Real world examples of data tensors.\n",
    "- *Vector data*: 2D tensors of shape (`samples`, `features`)\n",
    "- *Timeseries data or sequence data*: 3D tensors of shape (`samples`, `timesteps`,`features`). Te time axis is always the second axis (axis of index 1).\n",
    "- *Images*: 4D tensors of shape (`samples`, `height`, `width`, `channels`) or (`samples`, `channels`, `height`, `width`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Broadcasting\n",
    "What happens with addition when the shapes of the two tensors being added differ?\n",
    "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to match the shape of the larger tensor. Broadcasting consists of two steps:\n",
    "- Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "- The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor.\n",
    "\n",
    "With broadcasting, you can generally apply two-tensor element-wise operations if one tensor has shape `(a,b,... n,n+1,... m)` and the other has shape `(n,n+1,... m)`. The broadcasting will then automatically happen for axes a through `n - 1`.\n",
    "The following example applies the element-wise maximum operation to two tensors of different shapes via broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A geometric interpretation of deep learning\n",
    "You just learned that neural networks consist entirely of chains of tensor operations and that all of these tensor operations are just geometric transformations of the input data. It follows that you can interpret a neural network as a very complex geometric transfor- mation in a high-dimensional space, implemented via a long series of simple steps.\n",
    "In 3D, the following mental image may prove useful. Imagine two sheets of colored paper: one red and one blue. Put one on top of the other. Now crumple them together into a small ball. That crumpled paper ball is your input data, and each sheet of paper is a class of data in a classification problem. What a neural network (or any other machine-learning model) is meant to do is figure out a transformation of the paper ball that would uncrumple it, so as to make the two classes cleanly separable again. With deep learning, this would be implemented as a series of simple transfor- mations of the 3D space, such as those you could apply on the paper ball with your fin- gers, one movement at a time.\n",
    "\n",
    "Uncrumpling paper balls is what machine learning is about: finding neat representa- tions for complex, highly folded data manifolds. At this point, you should have a pretty good intuition as to why deep learning excels at this: it takes the approach of incrementally decomposing a complicated geometric transformation into a long chain of elementary ones, which is pretty much the strategy a human would follow to uncrumple a paper ball. Each layer in a deep network applies a transformation that disentangles the data a little—and a deep stack of layers makes tractable an extremely complicated disentanglement process.\n",
    "\n",
    "Before we describre the differents optimization algorithms, I would like to make clear a main concept that it will be repeated as a loop, and is the most important step in neural networks training process. This import step is called *update the parameters*. First, training data is feed to the neural network, so the prediction for each sample is computed (feedforward process). Next, the cost function is computed for all the predictions. Then, the partial derivatives of the cost function with respect to the parameters are computed. Finally, the parameters are updated by the following general expression:\n",
    "\\begin{equation*}\n",
    "w_i^{k+1} = w_i^k - \\eta \\dfrac{\\partial{C}}{\\partial{w_i}}\\, \\quad \\eta: \\text{learning rate} \\quad\n",
    "\\end{equation*}\n",
    "The optimization process consist in update the network's parameters and reach the global minimum of the cost function. The way to get it, it depends on how to update the parameters. For example, computing the partial derivatives with all the samples at the same time, it costs much resources than using a single sample. On the other hand, this way is the slowlest way to update the parameters. Let's define the first three most known algorithms:\n",
    "- Gradient descent (GD): The step *update the parameters* (feedforward + backpropagation) is performed for the whole dataset at once, so $w_i^{k+1} = w_i^k - \\eta\\bigg(\\frac{1}{N}\\sum_{j=1}^{N} \\dfrac{\\partial{C^j}}{\\partial{w_i}}\\bigg)$, where $N$ is the number of samples in the dataset.\n",
    "- Stochastic gradient descent (SGD):\n",
    "- Mini-batch stochastic gradient descent (Mini_batch SGD): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
